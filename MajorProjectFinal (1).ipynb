{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "XmlI0mPbwcKf"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit google-generativeai pyngrok --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD8CpgGFraY-pZFKNN4CLjjGkHqHOhIX-c\"  # Replace with your Gemini API key\n"
      ],
      "metadata": {
        "id": "dA61eL2PwoxP"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile emotion_detector.py\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "model = genai.GenerativeModel(\"gemini-2.5-flash-lite\")\n",
        "\n",
        "def detect_emotion(text):\n",
        "    prompt = f\"Detect the dominant emotion from this text: '{text}'. Respond with one word like 'fear', 'joy', 'sadness', 'anger', or 'surprise'.\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip().lower()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKP6xpmjwrJG",
        "outputId": "fe14b46e-3116-4c3d-c6be-b792fb0aef89"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting emotion_detector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile story_generator.py\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "model = genai.GenerativeModel(\"gemini-2.5-flash-lite\")\n",
        "\n",
        "def continue_story(scene, emotion):\n",
        "    prompt = (\n",
        "        f\"Continue this story in the tone of {emotion}. Make it emotionally rich and realistic.\\n\\n\"\n",
        "        f\"Scene: {scene}\\n\\n\"\n",
        "        f\"Continuation:\"\n",
        "    )\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20oXxx4kwuKG",
        "outputId": "253769ec-e9f7-49a8-a2b9-f0c90a96de63"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting story_generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile image_generator.py\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "import torch\n",
        "\n",
        "# Load the model\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/sdxl-turbo\",\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    variant=\"fp16\" if torch.cuda.is_available() else None,\n",
        "    use_safetensors=True\n",
        ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def generate_emotion_image(prompt, emotion):\n",
        "    styled_prompt = (\n",
        "        f\"Highly detailed, cinematic, ultra-realistic of a real human showing strong {emotion.lower()} emotion. \"\n",
        "        f\"{prompt}, expressive facial features matching the emotion, dramatic but natural lighting, realistic background, \"\n",
        "        f\"35mm photography, shallow depth of field, photorealism, 8k resolution\"\n",
        "    )\n",
        "    result = pipe(prompt=styled_prompt, guidance_scale=1.5, num_inference_steps=4)\n",
        "    image = result.images[0]\n",
        "    filename = f\"{emotion.lower()}_image.png\"\n",
        "    image.save(filename)\n",
        "    return filename\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0z1IsNGwxLY",
        "outputId": "a726b705-926f-412d-f4dc-2bce03ef482e"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting image_generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile image_prompt_generator.py\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "model = genai.GenerativeModel(\"gemini-2.5-flash-lite\")\n",
        "\n",
        "def generate_image_prompt(scene, emotion):\n",
        "    prompt = (\n",
        "        f\"Generate a detailed visual prompt for an image showing the emotion '{emotion}' in the following scene:\\n\\n\"\n",
        "        f\"{scene}\\n\\n\"\n",
        "        f\"Make sure the facial expressions and environment reflect the emotion clearly.\"\n",
        "    )\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNCmb9DE_RKo",
        "outputId": "e8dd81fb-920a-4f76-a21c-76577651a1ef"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting image_prompt_generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from emotion_detector import detect_emotion\n",
        "from story_generator import continue_story\n",
        "from image_prompt_generator import generate_image_prompt\n",
        "from image_generator import generate_emotion_image\n",
        "\n",
        "st.set_page_config(page_title=\"Emotion-Aware Story Generator\", layout=\"centered\")\n",
        "st.title(\"ðŸŽ­ Emotion-Aware AI Story Assistant\")\n",
        "\n",
        "scene_input = st.text_area(\"Enter the opening scene:\", height=150)\n",
        "\n",
        "if st.button(\"Generate\"):\n",
        "    if not scene_input.strip():\n",
        "        st.error(\"Please enter some text to analyze.\")\n",
        "    else:\n",
        "        with st.spinner(\"Detecting emotion...\"):\n",
        "            emotion = detect_emotion(scene_input)\n",
        "            st.success(f\"Detected Emotion: **{emotion.capitalize()}**\")\n",
        "\n",
        "        with st.spinner(\"Generating continuation...\"):\n",
        "            continuation = continue_story(scene_input, emotion)\n",
        "            st.subheader(\"ðŸ“˜ Continued Story\")\n",
        "            st.write(continuation)\n",
        "\n",
        "        with st.spinner(\"Generating visual prompt...\"):\n",
        "            img_prompt = generate_image_prompt(scene_input, emotion)\n",
        "            st.text(\"Prompt used for image generation:\")\n",
        "            st.write(img_prompt)\n",
        "\n",
        "        with st.spinner(\"Generating image...\"):\n",
        "            image_path = generate_emotion_image(scene_input,emotion)\n",
        "            st.image(image_path, caption=f\"Generated image for '{emotion}'\", use_container_width=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWWscqHLzTA8",
        "outputId": "d25b6e1e-5544-4c38-87a0-163148e6649b"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken $30ttouU1Ge5YlOa3heZ8CMvshl4_2guUo9MUPdEwCK5Su9n6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b8i7qa_6Ukj",
        "outputId": "da79da24-36df-46d2-be41-0793b26720da"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Set your Ngrok authtoken\n",
        "ngrok.set_auth_token(\"30ttouU1Ge5YlOa3heZ8CMvshl4_2guUo9MUPdEwCK5Su9n6\")\n",
        "\n",
        "# Kill any existing tunnels (just in case)\n",
        "ngrok.kill()\n",
        "\n",
        "# Expose the Streamlit port (7860)\n",
        "public_url = ngrok.connect(7860) # Pass the port directly\n",
        "print(f\"ðŸš€ Public link: {public_url}\")\n",
        "\n",
        "# Run the Streamlit app\n",
        "!streamlit run app.py --server.port 7860 --server.enableCORS false"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XTIU6cFzNmB",
        "outputId": "4b97b6bb-9325-4bac-f5d1-374dd8ec52bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Public link: NgrokTunnel: \"https://753dda679bbc.ngrok-free.app\" -> \"http://localhost:7860\"\n",
            "2025-08-06 08:30:59.956 \n",
            "Warning: the config option 'server.enableCORS=false' is not compatible with\n",
            "'server.enableXsrfProtection=true'.\n",
            "As a result, 'server.enableCORS' is being overridden to 'true'.\n",
            "\n",
            "More information:\n",
            "In order to protect against CSRF attacks, we send a cookie with each request.\n",
            "To do so, we must specify allowable origins, which places a restriction on\n",
            "cross-origin resource sharing.\n",
            "\n",
            "If cross origin resource sharing is required, please disable server.enableXsrfProtection.\n",
            "            \n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:7860\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:7860\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.204.243.208:7860\u001b[0m\n",
            "\u001b[0m\n",
            "2025-08-06 08:31:41.321294: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754469101.396499   52343 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754469101.417770   52343 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Loading pipeline components...: 100% 7/7 [00:07<00:00,  1.05s/it]\n",
            "100% 4/4 [08:49<00:00, 132.31s/it]\n"
          ]
        }
      ]
    }
  ]
}